{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd49b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import curve_fit \n",
    "\n",
    "# imports of our code \n",
    "from load_models import *\n",
    "import LocalLearning_copy as LocalLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e602df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a4f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters:\n",
    "BATCH_SIZE = 1000\n",
    "NUMBER_OF_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# loss function\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4245e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10Train= LocalLearning.LpUnitCIFAR10(\n",
    "            root=\"../data/CIFAR10\",\n",
    "            train=True,\n",
    "            transform=ToTensor(),\n",
    "            p=3.0,\n",
    "        )\n",
    "\n",
    "cifar10Test= LocalLearning.LpUnitCIFAR10(\n",
    "            root=\"../data/CIFAR10\",\n",
    "            train=False,\n",
    "            transform=ToTensor(),\n",
    "            p=3.0,\n",
    "        )\n",
    "\n",
    "TestLoader = LocalLearning.DeviceDataLoader(\n",
    "            cifar10Test,\n",
    "            device=device,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "TrainLoader = LocalLearning.DeviceDataLoader(\n",
    "            cifar10Train,\n",
    "            device=device,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ba2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_critirium(\n",
    "    dataloader,\n",
    "    model, \n",
    "    crit,\n",
    "    thres = None\n",
    "    ):\n",
    "    \n",
    "    # Returns the data and the corresponding labels that meets the critirium given (crit)\n",
    "    \n",
    "    freq_correct = 0\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    \n",
    "    data = torch.zeros((0,32,32,3)).to(device)\n",
    "    lab_data = torch.zeros((0)).to(device)\n",
    "    \n",
    "    for batch_no, (features, labels) in enumerate(dataloader):\n",
    "        preds = model(features)\n",
    "        pred = torch.argmax(preds, dim=-1)\n",
    "        \n",
    "        if crit == \"correct\":\n",
    "            filtr_idx = (torch.abs(pred - labels) == 0)\n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "        \n",
    "        elif crit == \"correct_thres\":\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            thres_idx = (softmax_correct >= thres)\n",
    "            correct_idx = (torch.abs(pred - labels) == 0)\n",
    "            filtr_idx = thres_idx & correct_idx \n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "            \n",
    "        elif crit == \"thres\":\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            filtr_idx = (softmax_correct >= thres)\n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "            \n",
    "        else: \n",
    "            raise ValueError(\"Not a valid criterium\")\n",
    "    \n",
    "    return data, lab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4351411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack(\n",
    "    features,\n",
    "    labels, \n",
    "    model, \n",
    "    attack,\n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    eps=None,\n",
    "    std=None,\n",
    "    ):\n",
    "    \n",
    "    freq_correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    labels = labels.type(torch.LongTensor).to(device)\n",
    "    features.requires_grad = True\n",
    "    \n",
    "    if attack == \"FGSM\":\n",
    "        perturbed = FGSM(model, features, labels, loss_fn, optimizer, eps)\n",
    "        \n",
    "    elif attack == \"PGD\":\n",
    "        perturbed, epsilon = PGD(model, features, labels, loss_fn, optimizer, \n",
    "                                 num_steps=20, step_size=0.01, b_norm=0.3)\n",
    "        \n",
    "    elif attack == \"WN\":\n",
    "        pass \n",
    "        \n",
    "    else: \n",
    "        raise ValueError(\"Not a valid attack\")\n",
    "        \n",
    "    preds_perturbed = torch.argmax(model(perturbed), dim=-1)\n",
    "    alike = (preds_perturbed == labels)\n",
    "    freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "    total += len(labels)\n",
    "\n",
    "    correct = (freq_correct/total).item()\n",
    "    \n",
    "    return correct, alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b4f836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit_eps_pgd(criterium, model, print_accuracy):\n",
    "    \n",
    "    features, labels = data_critirium(TestLoader, model, criterium)\n",
    "    labels = labels.type(torch.LongTensor).to(device)\n",
    "    features.requires_grad = True\n",
    "    \n",
    "    siz = len(labels)\n",
    "\n",
    "    crit_eps_per_image = torch.ones(siz).to(device)\n",
    "    crit_eps_per_image[:] = 0.05 #epslist[-1]\n",
    "\n",
    "    freq_correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    num_steps = 100\n",
    "    loss_fn = ce_loss \n",
    "    step_size = 0.0005\n",
    "    b_norm = 0.05\n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    correct = []\n",
    "\n",
    "    perturbed_image = features \n",
    "\n",
    "    for n in range(num_steps):\n",
    "        preds = model(features)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv_image = perturbed_image + step_size*features.grad.data.sign()\n",
    "        clamp = torch.clamp(adv_image - features, min = -b_norm, max = b_norm)\n",
    "        perturbed_image = torch.clamp(features + clamp, min = 0, max = 1)\n",
    "\n",
    "        preds_perturbed = torch.argmax(model(perturbed_image), dim=-1)\n",
    "        alike = (preds_perturbed == labels)\n",
    "        freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "        total += len(labels)\n",
    "\n",
    "        correct.append((freq_correct/total).item())\n",
    "\n",
    "        mask = (alike == False) & (crit_eps_per_image == 0.05) #epslist[-1])\n",
    "\n",
    "        x = features.view(features.size(0),-1)\n",
    "        y = perturbed_image.view(perturbed_image.size(0),-1)\n",
    "\n",
    "        eps = torch.abs(torch.mean(x-y,dim=1)).detach()\n",
    "        crit_eps_per_image[mask] = eps[mask]\n",
    "        \n",
    "    crit_eps_per_image = np.array(crit_eps_per_image.cpu())\n",
    "    \n",
    "    if print_accuracy == True:\n",
    "        print(f\"{correct[-1]*100:.2f}% is still correctly classified\")\n",
    "        \n",
    "    # consider adding an if-statement for continuing to attck if the accuracy is to high\n",
    "    # must be the same for both ll and bp model in order to compare \n",
    "\n",
    "    return crit_eps_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddecd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_epsilon(criterium, model, attack, print_accuracy = False):\n",
    "    if attack == \"PGD\":\n",
    "        crit_eps = crit_eps_pgd(criterium, model, print_accuracy)\n",
    "        \n",
    "    elif attack == \"FGSM\":\n",
    "        pass\n",
    "    \n",
    "    elif attack == \"WN\":\n",
    "        pass \n",
    "    \n",
    "    else: \n",
    "        raise ValueError(\"Not a valid attack\")\n",
    "        \n",
    "    return crit_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4092fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(ll_crit_eps, bp_crit_eps, attack): \n",
    "\n",
    "    plt.boxplot((ll_crit_eps, bp_crit_eps), showfliers=False)\n",
    "    plt.xticks([1,2],[\"LL\",\"BP\"])\n",
    "    plt.ylabel(\"Critical epsilon\")\n",
    "    plt.title(\"Konstantin model \" + attack + \" attack\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd7e745e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.70 GiB total capacity; 17.94 GiB already allocated; 10.81 MiB free; 18.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# functions for downloading models in load_models.py \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bp_modelK \u001b[38;5;241m=\u001b[39m \u001b[43mload_Konstantin_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbp_KHModel_kh_layer_cifar10.pty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m ll_modelK \u001b[38;5;241m=\u001b[39m load_Konstantin_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mll_KHModel_kh_layer_cifar10.pty\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mll\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Mia/LocalLearning/notebooks/load_models.py:57\u001b[0m, in \u001b[0;36mload_Konstantin_model\u001b[0;34m(file_name, model_type)\u001b[0m\n\u001b[1;32m     54\u001b[0m     modeltype \u001b[38;5;241m=\u001b[39m LocalLearning\u001b[38;5;241m.\u001b[39mKHModel\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 57\u001b[0m     trained_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model_path\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     model_ps \u001b[38;5;241m=\u001b[39m trained_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfkhl3-state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     59\u001b[0m     model \u001b[38;5;241m=\u001b[39m modeltype(model_ps)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/serialization.py:157\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_UntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_utils.py:78\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_UntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.70 GiB total capacity; 17.94 GiB already allocated; 10.81 MiB free; 18.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# functions for downloading models in load_models.py \n",
    "bp_modelK = load_Konstantin_model(\"bp_KHModel_kh_layer_cifar10.pty\",\"bp\")\n",
    "ll_modelK = load_Konstantin_model(\"ll_KHModel_kh_layer_cifar10.pty\",\"ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "967cdb96",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 23.70 GiB total capacity; 17.94 GiB already allocated; 10.81 MiB free; 18.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m criteps_bp \u001b[38;5;241m=\u001b[39m \u001b[43mcritical_epsilon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcorrect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbp_modelK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPGD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m criteps_ll \u001b[38;5;241m=\u001b[39m critical_epsilon(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m, ll_modelK, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPGD\u001b[39m\u001b[38;5;124m\"\u001b[39m, print_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m boxplot(criteps_ll, criteps_bp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPGD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m, in \u001b[0;36mcritical_epsilon\u001b[0;34m(criterium, model, attack, print_accuracy)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcritical_epsilon\u001b[39m(criterium, model, attack, print_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attack \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPGD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         crit_eps \u001b[38;5;241m=\u001b[39m \u001b[43mcrit_eps_pgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterium\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_accuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m attack \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFGSM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[96], line 3\u001b[0m, in \u001b[0;36mcrit_eps_pgd\u001b[0;34m(criterium, model, print_accuracy)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrit_eps_pgd\u001b[39m(criterium, model, print_accuracy):\n\u001b[0;32m----> 3\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata_critirium\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTestLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterium\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     features\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mdata_critirium\u001b[0;34m(dataloader, model, crit, thres)\u001b[0m\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m lab_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_no, (features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     18\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 23.70 GiB total capacity; 17.94 GiB already allocated; 10.81 MiB free; 18.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "criteps_bp = critical_epsilon(\"correct\", bp_modelK, \"PGD\", print_accuracy=True)\n",
    "criteps_ll = critical_epsilon(\"correct\", ll_modelK, \"PGD\", print_accuracy=True)\n",
    "boxplot(criteps_ll, criteps_bp, \"PGD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
