{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f311fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import curve_fit \n",
    "\n",
    "# imports of our code \n",
    "from load_models import *\n",
    "import LocalLearning_copy as LocalLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1711c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8542c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters:\n",
    "BATCH_SIZE = 1000\n",
    "NUMBER_OF_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# loss function\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3290c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10Train= LocalLearning.LpUnitCIFAR10(\n",
    "            root=\"../data/CIFAR10\",\n",
    "            train=True,\n",
    "            transform=ToTensor(),\n",
    "            p=3.0,\n",
    "        )\n",
    "\n",
    "cifar10Test= LocalLearning.LpUnitCIFAR10(\n",
    "            root=\"../data/CIFAR10\",\n",
    "            train=False,\n",
    "            transform=ToTensor(),\n",
    "            p=3.0,\n",
    "        )\n",
    "\n",
    "TestLoader = LocalLearning.DeviceDataLoader(\n",
    "            cifar10Test,\n",
    "            device=device,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "TrainLoader = LocalLearning.DeviceDataLoader(\n",
    "            cifar10Train,\n",
    "            device=device,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5aeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for downloading models in load_models.py \n",
    "bp_modelK = load_Konstantin_model(\"bp_KHModel_kh_layer_cifar10.pty\",\"bp\")\n",
    "ll_modelK = load_Konstantin_model(\"ll_KHModel_kh_layer_cifar10.pty\",\"ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b3777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_total(\n",
    "    test: DataLoader,\n",
    "    model: LocalLearning.KHModel, \n",
    "    thres,\n",
    "    crit=None\n",
    "    ):\n",
    "    \n",
    "    freq_correct = 0\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    for batch_no, (features, labels) in enumerate(test):\n",
    "        preds = model(features)\n",
    "        pred = torch.argmax(preds, dim=-1)\n",
    "        \n",
    "        if crit == \"correct_thres\":\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            thres_idx = (softmax_correct >= thres)\n",
    "            correct_idx = (torch.abs(pred - labels) == 0)\n",
    "            filtr_idx = thres_idx & correct_idx \n",
    "            new_preds = pred[filtr_idx]\n",
    "            new_labels = labels[filtr_idx]\n",
    "            total += len(new_labels)\n",
    "            \n",
    "        elif crit == \"thres\": # HÃ¥kon Olav uses 0.8 as threshold\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            thres_idx = (softmax_correct >= thres)\n",
    "            new_preds = pred[thres_idx]\n",
    "            new_labels = labels[thres_idx]\n",
    "            total += len(new_labels)\n",
    "            \n",
    "        elif crit == \"correct\": \n",
    "            correct_idx = (torch.abs(pred - labels) == 0)\n",
    "            new_preds = pred[correct_idx]\n",
    "            new_labels = labels[correct_idx]\n",
    "            total += len(new_labels)\n",
    "            \n",
    "        elif crit == None:\n",
    "            new_preds = torch.argmax(preds,axis=1)\n",
    "            new_labels = labels\n",
    "            total += len(new_labels)\n",
    "        \n",
    "        freq_correct += (torch.abs(new_preds - new_labels) == 0).sum()\n",
    "        \n",
    "    correct = (freq_correct / total).item()\n",
    "    \n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4570c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_total_n_models(n,modeltype,dataloader,thres,crit=None):\n",
    "    list_acc = []\n",
    "    list_n = []\n",
    "    \n",
    "    if modeltype == \"bp\": \n",
    "        for i in tqdm(range(n)):\n",
    "            model = load_trained_model_bp(i)\n",
    "            correct, total = acc_total(dataloader, model, thres, crit)\n",
    "            list_acc.append(correct)\n",
    "            list_n.append(total)\n",
    "        \n",
    "    if modeltype == \"ll\": \n",
    "        for i in tqdm(range(n)):\n",
    "            model = load_trained_model_ll(i)\n",
    "            correct, total = acc_total(dataloader, model, thres, crit)\n",
    "            list_acc.append(correct)\n",
    "            list_n.append(total)\n",
    "        \n",
    "    return list_acc, list_n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45fca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "dataloader = TestLoader\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61201dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_acc_normal, list_n_normal = acc_total_n_models(100,\"bp\",dataloader,0)\n",
    "#torch.save(list_acc_normal,\"../data/Mia_data/accuracy_all_bp_models.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "390cb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(n, model, dataloader, threshold, crit):\n",
    "    acc, tot = acc_total(n, model, dataloader, threshold, crit)\n",
    "    if crit == \"correct_thres\":\n",
    "        print(f\"Criterium = Correct and above 0.8\")\n",
    "        \n",
    "    elif crit == \"thres\":\n",
    "        print(f\"Criterium = Above 0.8\")\n",
    "\n",
    "    else: \n",
    "        print(f\"Criterium = Correct\")\n",
    "        \n",
    "    print(f\"Mean correct for {n} {model} models with Softmax >= {threshold} on training data : {np.mean(acc)*100:.2f} %\")\n",
    "    print(f\"Mean number of pictures = {np.mean(tot)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eff3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_critirium(\n",
    "    dataloader,\n",
    "    model, \n",
    "    crit,\n",
    "    thres = None\n",
    "    ):\n",
    "    \n",
    "    # Returns the data and the corresponding labels that meets the critirium given (crit)\n",
    "    \n",
    "    freq_correct = 0\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    \n",
    "    data = torch.zeros((0,32,32,3)).to(device)\n",
    "    lab_data = torch.zeros((0)).to(device)\n",
    "    \n",
    "    for batch_no, (features, labels) in enumerate(dataloader):\n",
    "        preds = model(features)\n",
    "        pred = torch.argmax(preds, dim=-1)\n",
    "        \n",
    "        if crit == \"correct\":\n",
    "            filtr_idx = (torch.abs(pred - labels) == 0)\n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "        \n",
    "        elif crit == \"correct_thres\":\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            thres_idx = (softmax_correct >= thres)\n",
    "            correct_idx = (torch.abs(pred - labels) == 0)\n",
    "            filtr_idx = thres_idx & correct_idx \n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "            \n",
    "        else:\n",
    "            softmax_correct = (preds[torch.arange(1000),pred])\n",
    "            filtr_idx = (softmax_correct >= thres)\n",
    "            new_features = features[filtr_idx]\n",
    "            data = torch.cat((data, new_features),dim=0)\n",
    "            new_labels = labels[filtr_idx]\n",
    "            lab_data = torch.cat((lab_data, new_labels),dim=0)\n",
    "    \n",
    "    return data, lab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4aa3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(model, features, labels, loss_fn, optimizer, epsilon):\n",
    "    \n",
    "    preds = model(features)\n",
    "    loss = loss_fn(preds, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_image = features + epsilon*features.grad.data.sign()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5badf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack(\n",
    "    features,\n",
    "    labels, \n",
    "    model, \n",
    "    attack,\n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    eps=None,\n",
    "    std=None,\n",
    "    ):\n",
    "    \n",
    "    freq_correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    labels = labels.type(torch.LongTensor).to(device)\n",
    "    features.requires_grad = True\n",
    "    \n",
    "    if attack == \"FGSM\":\n",
    "        perturbed = FGSM(model, features, labels, loss_fn, optimizer, eps)\n",
    "        \n",
    "    elif attack == \"PGD\":\n",
    "        perturbed, epsilon = PGD(model, features, labels, loss_fn, optimizer, \n",
    "                                 num_steps=20, step_size=0.01, b_norm=0.3)\n",
    "        \n",
    "    else: \n",
    "        print(\"Something went wrong\")\n",
    "        \n",
    "    preds_perturbed = torch.argmax(model(perturbed), dim=-1)\n",
    "    alike = (preds_perturbed == labels)\n",
    "    freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "    total += len(labels)\n",
    "\n",
    "    correct = (freq_correct/total).item()\n",
    "    \n",
    "    return correct, alike#, epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf0ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epslist = [0.0001*i for i in range(1,100)]\n",
    "\n",
    "def logistic(x,a,b,c,d):\n",
    "    return a/(1+np.exp(-c*(x-d)))+b\n",
    "\n",
    "def criteps_FGSM(n,modeltype,attacktype=\"FGSM\",plot=False,crit=None, epslist=epslist):\n",
    "    \n",
    "    if modeltype == \"ll\":\n",
    "    \n",
    "        ll = []\n",
    "        ll_crit_eps = []\n",
    "        ll_eps_half_max = []\n",
    "\n",
    "        for i in tqdm(range(n)):\n",
    "            model_ll = load_trained_model_ll(i)\n",
    "            data_ll, lab_ll = data_critirium(TestLoader, model_ll, \"correct_thres\", thres = 0.8)\n",
    "\n",
    "            AdamOpt_ll = Adam(model_ll.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "            list_ll = []\n",
    "\n",
    "            for eps in epslist:\n",
    "                correct, a, e = test_attack(data_ll, lab_ll, model_ll, attacktype, ce_loss, AdamOpt_ll, eps)\n",
    "                list_ll.append(float(correct))\n",
    "\n",
    "            ll.append(list_ll)\n",
    "\n",
    "            x = np.array(epslist)\n",
    "            y_ll = np.array(list_ll)\n",
    "\n",
    "            popt, pcov = curve_fit(logistic, x, y_ll)\n",
    "            critical_eps = popt[-1]\n",
    "\n",
    "            ll_crit_eps.append(critical_eps)\n",
    "\n",
    "            x_high_res = np.linspace(x[0],x[-1]+1,10000)\n",
    "            func = logistic(x_high_res,*popt)\n",
    "            half_max_idx = (np.abs(func-0.5)).argmin()\n",
    "            eps_half_max = x_high_res[half_max_idx]\n",
    "\n",
    "            ll_eps_half_max.append(eps_half_max)\n",
    "        \n",
    "        \n",
    "            if plot==True and i == 0:\n",
    "                plt.plot(x,y_ll)\n",
    "                plt.plot(x,logistic(x,*popt))\n",
    "                plt.plot(critical_eps,logistic(critical_eps,*popt),\"ro\",label=\"Inflection point of fitted curve\")\n",
    "                plt.plot(eps_half_max,func[half_max_idx],\"bo\",label=\"Fitted curve = 0.5\")\n",
    "                plt.title(\"FGSM on LL model\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "        \n",
    "                \n",
    "        return ll, ll_crit_eps, ll_eps_half_max\n",
    "    \n",
    "    elif modeltype == \"bp\":\n",
    "    \n",
    "        bp = []\n",
    "        bp_eps_half_max = []\n",
    "\n",
    "        for i in tqdm(range(n)):\n",
    "            model_bp = load_trained_model_bp(i)\n",
    "            data_bp, lab_bp = data_critirium(TestLoader, model_bp, correct_thres, thres = 0.8)\n",
    "\n",
    "            AdamOpt_bp = Adam(model_bp.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "            list_bp = []\n",
    "\n",
    "            for eps in epslist:\n",
    "                correct, a, e = test_attack(data_bp, lab_bp, model_bp, attacktype, ce_loss, AdamOpt_bp, eps)\n",
    "                list_bp.append(correct)\n",
    "\n",
    "            bp.append(list_bp)\n",
    "\n",
    "            x = np.array(epslist)\n",
    "            y_bp = np.array(list_bp)\n",
    "\n",
    "            popt, pcov = curve_fit(logistic, x, y_bp, p0=(1,0,1,0), maxfev = 10000)\n",
    "           \n",
    "            x_high_res = np.linspace(x[0],x[-1]+1,10000)\n",
    "            func = logistic(x_high_res,*popt)\n",
    "            half_max_idx = (np.abs(func-0.5)).argmin()\n",
    "            eps_half_max = x_high_res[half_max_idx]\n",
    "\n",
    "            bp_eps_half_max.append(eps_half_max)\n",
    "            \n",
    "            if plot==True and i == 0:\n",
    "                plt.plot(x,y_bp)\n",
    "                plt.plot(x,logistic(x,*popt))\n",
    "                #plt.plot(critical_eps,logistic(critical_eps,*popt),\"ro\",label=\"Inflection point of fitted curve\")\n",
    "                plt.plot(eps_half_max,func[half_max_idx],\"bo\",label=\"Fitted curve = 0.5\")\n",
    "                plt.title(\"FGSM on LL model\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "        return bp, \"Not defined\", bp_eps_half_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bbfaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ll,\"../data/Mia_data/accuracy_through_FGSM_all_ll_models.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36a49af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_423801/2370754762.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return a/(1+np.exp(-c*(x-d)))+b\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poptt = [5.61523970e+04,  5.74443460e-04, -9.22749104e+02, -1.18282523e-02]\n",
    "xarray = np.linspace(-5,5,10000)\n",
    "plt.plot(xarray,logistic(xarray,*poptt))\n",
    "critical_eps = -1.18282523e-02\n",
    "plt.plot(critical_eps,logistic(critical_eps,*poptt),\"ro\")\n",
    "plt.xlim(-0.03,0.01)\n",
    "plt.show()\n",
    "\n",
    "# In attempting to define the critical epsilon as the inflection point this happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c31f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(bp,\"../data/Mia_data/accuracy_through_FGSM_all_bp_models.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "625d176b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mbp\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bpeps)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bp' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(bp[0])\n",
    "print(bpeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(lleps,\"../data/Mia_data/critical_epsilons_ll_models.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_eps_ll = np.array(torch.load(\"../data/Mia_data/critical_epsilons_ll_models.pt\"))\n",
    "acc_ll = np.array(torch.load(\"../data/Mia_data/accuracy_all_ll_models.pt\"))\n",
    "\n",
    "acc_bp = np.array(torch.load(\"../data/Mia_data/accuracy_all_bp_models.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crit_eps_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf91811",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_eps_ll_spectra = crit_eps_ll[scales_stringer_spectra]\n",
    "acc_ll_spectra = acc_ll[scales_stringer_spectra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(crit_eps_ll,acc_ll)\n",
    "plt.scatter(crit_eps_ll_spectra,acc_ll_spectra,c=\"red\")\n",
    "plt.xlabel(\"Critical epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c480b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_fit_curve_at_half_ll = torch.load(\"../data/Mia_data/epsilon_fitted_curve_at_05_all_ll_models.pt\")\n",
    "eps_fit_curve_at_half_bp = torch.load(\"../data/Mia_data/epsilon_fitted_curve_at_05_all_bp_models.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(eps_fit_curve_at_half_ll))\n",
    "print(np.mean(eps_fit_curve_at_half_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14853101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit_eps_one_model_fgsm(modeltype,n=None,attack=\"FGSM\",epslist=epslist):\n",
    "    \n",
    "    #n = modelnumber\n",
    "    \n",
    "    if modeltype == \"ll\":\n",
    "    \n",
    "        ll_crit_eps = []\n",
    "        list_ll_correct_all = []\n",
    "\n",
    "        #model_ll = load_trained_model_ll(n)\n",
    "        model_ll = ll_modelK\n",
    "        data_ll, lab_ll = data_critirium(TestLoader, model_ll, \"correct\")#, thres = 0.8)\n",
    "        \n",
    "        siz = len(lab_ll)\n",
    "        \n",
    "        crit_eps_per_image = torch.ones(siz).to(device)\n",
    "        crit_eps_per_image[:] = epslist[-1]\n",
    "        \n",
    "        AdamOpt_ll = Adam(model_ll.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        for eps in epslist:\n",
    "            correct, alike = test_attack(data_ll, lab_ll, model_ll, attack, ce_loss, AdamOpt_ll, eps)\n",
    "            mask = (alike == False) & (crit_eps_per_image == epslist[-1])\n",
    "            crit_eps_per_image[mask] = eps\n",
    "            list_ll_correct_all.append(correct)\n",
    "\n",
    "        x = np.array(epslist)\n",
    "        y_ll = np.array(list_ll_correct_all)\n",
    "\n",
    "        popt, pcov = curve_fit(logistic, x, y_ll)\n",
    "        critical_eps = popt[-1]\n",
    "\n",
    "        ll_crit_eps.append(critical_eps)\n",
    "        \n",
    "        crit_eps_per_image = np.array(crit_eps_per_image.cpu())\n",
    "                        \n",
    "        return crit_eps_per_image #, list_ll_correct_all, ll_crit_eps\n",
    "    \n",
    "    if modeltype == \"bp\":\n",
    "    \n",
    "        bp_crit_eps = []\n",
    "        list_bp_correct_all = []\n",
    "\n",
    "        #model_bp = load_trained_model_bp(n)\n",
    "        model_bp = bp_modelK\n",
    "        data_bp, lab_bp = data_critirium(TestLoader, model_bp, \"correct\")#, thres = 0.8)\n",
    "        \n",
    "        siz = len(lab_bp)\n",
    "        \n",
    "        crit_eps_per_image = torch.ones(siz).to(device)\n",
    "        crit_eps_per_image[:] = epslist[-1]\n",
    "        \n",
    "        AdamOpt_bp = Adam(model_bp.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        for eps in epslist:\n",
    "            correct, alike = test_attack(data_bp, lab_bp, model_bp, attack, ce_loss, AdamOpt_bp, eps)\n",
    "            mask = (alike == False) & (crit_eps_per_image == epslist[-1])\n",
    "            crit_eps_per_image[mask] = eps\n",
    "            list_bp_correct_all.append(correct)\n",
    "\n",
    "        x = np.array(epslist)\n",
    "        y_bp = np.array(list_bp_correct_all)\n",
    "\n",
    "        popt, pcov = curve_fit(logistic, x, y_bp)\n",
    "        critical_eps = popt[-1]\n",
    "\n",
    "        bp_crit_eps.append(critical_eps)\n",
    "        \n",
    "        crit_eps_per_image = np.array(crit_eps_per_image.cpu())\n",
    "        \n",
    "        return crit_eps_per_image #, list_bp_correct_all, bp_crit_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(model, features, labels, loss_fn, optimizer, num_steps=20, step_size=0.01, b_norm=0.3):\n",
    "    \n",
    "    for n in range(num_steps):\n",
    "        preds = model(features)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        adv_image = features + step_size*features.grad.data.sign()\n",
    "        clamp = torch.clamp(adv_image - features, min = -b_norm, max = b_norm)\n",
    "        perturbed_image = torch.clamp(features + clamp, min = 0, max = 1)\n",
    "        \n",
    "        preds_perturbed = torch.argmax(model(perturbed_image), dim=-1)\n",
    "        alike = (preds_perturbed == labels)\n",
    "        freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "        total += len(labels)\n",
    "\n",
    "        correct = (freq_correct/total).item()\n",
    "\n",
    "        mask = (alike == False) & (crit_eps_per_image == epslist[-1])\n",
    "        crit_eps_per_image[mask] = epsilon[mask]\n",
    "        \n",
    "    #x = features.view(features.size(0),-1)\n",
    "    #y = perturbed_image.view(perturbed_image.size(0),-1)\n",
    "    \n",
    "    #eps = torch.abs(torch.mean(x-y,dim=1)).detach()\n",
    "    \n",
    "    return perturbed_image, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit_eps_one_image_pgd(modeltype,n=None):\n",
    "    \n",
    "    attack = \"PGD\"\n",
    "    \n",
    "    if modeltype == \"ll\":\n",
    "        \n",
    "        model = ll_modelK\n",
    "        \n",
    "    elif modeltype == \"bp\":\n",
    "        \n",
    "        model = bp_modelK\n",
    "    \n",
    "    ll_crit_eps = []\n",
    "    list_ll_correct_all = []\n",
    "\n",
    "    #model = load_trained_model_ll(n)\n",
    "    features, labels = data_critirium(TestLoader, model, \"correct\")\n",
    "\n",
    "    siz = len(labels)\n",
    "\n",
    "    crit_eps_per_image = torch.ones(siz).to(device)\n",
    "    crit_eps_per_image[:] = 0.0099 #epslist[-1]\n",
    "\n",
    "    freq_correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    labels = labels.type(torch.LongTensor).to(device)\n",
    "    features.requires_grad = True\n",
    "\n",
    "    num_steps = 100\n",
    "    loss_fn = ce_loss \n",
    "    step_size = 0.0005\n",
    "    b_norm = 0.05\n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    correct = []\n",
    "\n",
    "    perturbed_image = features \n",
    "\n",
    "    for n in range(num_steps):\n",
    "        preds = model(features)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv_image = perturbed_image + step_size*features.grad.data.sign()\n",
    "        clamp = torch.clamp(adv_image - features, min = -b_norm, max = b_norm)\n",
    "        perturbed_image = torch.clamp(features + clamp, min = 0, max = 1)\n",
    "\n",
    "        preds_perturbed = torch.argmax(model(perturbed_image), dim=-1)\n",
    "        alike = (preds_perturbed == labels)\n",
    "        freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "        total += len(labels)\n",
    "\n",
    "        correct.append((freq_correct/total).item())\n",
    "\n",
    "        mask = (alike == False) & (crit_eps_per_image == 0.0099) #epslist[-1])\n",
    "\n",
    "        x = features.view(features.size(0),-1)\n",
    "        y = perturbed_image.view(perturbed_image.size(0),-1)\n",
    "\n",
    "        eps = torch.abs(torch.mean(x-y,dim=1)).detach()\n",
    "        crit_eps_per_image[mask] = eps[mask]\n",
    "        \n",
    "    crit_eps_per_image = np.array(crit_eps_per_image.cpu())\n",
    "\n",
    "    #perturbed, epsilon = PGD(model, features, labels, ce_loss, AdamOpt_ll, num_steps=20, step_size=0.01, b_norm=0.3)\n",
    "\n",
    "    return crit_eps_per_image, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25959a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit_eps_one_image_noise(modeltype,n=None):\n",
    "    \n",
    "    attack = \"WN\" # WN = White noise\n",
    "    \n",
    "    if modeltype == \"ll\":\n",
    "        \n",
    "        model = ll_modelK\n",
    "        \n",
    "    elif modeltype == \"bp\":\n",
    "        \n",
    "        model = bp_modelK\n",
    "    \n",
    "    ll_crit_eps = []\n",
    "\n",
    "    #model = load_trained_model_ll(n)\n",
    "    features, labels = data_critirium(TestLoader, model, \"correct\")\n",
    "\n",
    "    siz = len(labels)\n",
    "    \n",
    "    epslistwn = [0.01*i for i in range(1,200)]\n",
    "\n",
    "    crit_eps_per_image = torch.ones(siz).to(device)\n",
    "    crit_eps_per_image[:] = epslistwn[-1]\n",
    "\n",
    "    freq_correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    labels = labels.type(torch.LongTensor).to(device)\n",
    "    features.requires_grad = True\n",
    "\n",
    "    loss_fn = ce_loss \n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    correct = []\n",
    "    noise = torch.randn(features.shape).to(device)\n",
    "\n",
    "    for eps in epslistwn:\n",
    "        \n",
    "        adv_image = features + eps*noise\n",
    "        perturbed_image = torch.clamp(adv_image, min = 0, max = 1)\n",
    "\n",
    "        preds_perturbed = torch.argmax(model(perturbed_image), dim=-1)\n",
    "        alike = (preds_perturbed == labels)\n",
    "        freq_correct += (torch.abs(preds_perturbed - labels) == 0).sum()\n",
    "        total += len(labels)\n",
    "\n",
    "        correct.append((freq_correct/total).item())\n",
    "\n",
    "        mask = (alike == False) & (crit_eps_per_image == epslistwn[-1])\n",
    "\n",
    "        x = features.view(features.size(0),-1)\n",
    "        y = perturbed_image.view(perturbed_image.size(0),-1)\n",
    "\n",
    "        eps = torch.abs(torch.mean(x-y,dim=1)).detach()\n",
    "        \n",
    "        crit_eps_per_image[mask] = eps[mask]\n",
    "        \n",
    "    crit_eps_per_image = np.array(crit_eps_per_image.cpu())\n",
    "\n",
    "    #perturbed, epsilon = PGD(model, features, labels, ce_loss, AdamOpt_ll, num_steps=20, step_size=0.01, b_norm=0.3)\n",
    "\n",
    "    return crit_eps_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_crit_eps_pgd, correct = crit_eps_one_image_pgd(modeltype = \"ll\")\n",
    "bp_crit_eps_pgd, correct = crit_eps_one_image_pgd(modeltype = \"bp\")\n",
    "\n",
    "plt.boxplot((ll_crit_eps_pgd, bp_crit_eps_pgd), showfliers=False)\n",
    "plt.xticks([1,2],[\"LL\",\"BP\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(f\"Konstantin model PGD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_crit_eps_fgsm = crit_eps_one_model_fgsm(modeltype = \"ll\")\n",
    "bp_crit_eps_fgsm = crit_eps_one_model_fgsm(modeltype = \"bp\")\n",
    "\n",
    "plt.boxplot((ll_crit_eps_fgsm, bp_crit_eps_fgsm), showfliers=False)\n",
    "plt.xticks([1,2],[\"LL\",\"BP\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(f\"Konstantin model FGSM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_crit_eps_wn = crit_eps_one_image_noise(modeltype = \"ll\")\n",
    "bp_crit_eps_wn = crit_eps_one_image_noise(modeltype = \"bp\")\n",
    "\n",
    "plt.boxplot((ll_crit_eps_wn, bp_crit_eps_wn), showfliers=False)\n",
    "plt.xticks([1,2],[\"LL\",\"BP\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(f\"Konstantin model white noise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((crit_eps_per_image==0.0099).sum())\n",
    "print((crit_eps_per_image!=0.0099).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(correct)\n",
    "plt.title(\"Percentage of correctly classified images for one model\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.show()\n",
    "# all are classified corretly from start\n",
    "# once it is misclassified, it remains so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4c3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_per_image_ll = []\n",
    "for n in tqdm(range(100)):\n",
    "    crit_eps_per, correct = crit_eps_one_image_pgd(modeltype = \"ll\", n = 1)\n",
    "    all_models_per_image_ll.append(np.array(crit_eps_per.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eafbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(np.array(crit_eps_per.cpu()), showfliers=False)\n",
    "#plt.xticks([1,2],[\"BP\",\"LL\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(f\"Model number {1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_per_image_bp = []\n",
    "for n in tqdm(range(100)):\n",
    "    crit_eps_per = crit_eps_one_model(\"bp\",n,FGSM)\n",
    "    all_models_per_image_bp.append(np.array(crit_eps_per.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476056c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_per_image_ll_pgd = []\n",
    "for n in tqdm(range(100)):\n",
    "    crit_eps_per = crit_eps_one_model(\"ll\",n,PGD)\n",
    "    all_models_per_image_ll_pgd.append(np.array(crit_eps_per.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e494127",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_per_image_bp_pgd = []\n",
    "for n in tqdm(range(100)):\n",
    "    crit_eps_per = crit_eps_one_model(\"bp\",n,PGD)\n",
    "    all_models_per_image_bp_pgd.append(np.array(crit_eps_per.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epslist = [0.0001*i for i in range(1,100)]\n",
    "crit_eps_bp = crit_eps_one_model(\"bp\",n,FGSM,long_epslist)\n",
    "crit_eps_ll = crit_eps_one_model(\"ll\",n,FGSM,long_epslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_eps = long_epslist[-1]\n",
    "corr = (howlong_ll==last_eps)\n",
    "print(torch.sum(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d77913",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "plt.boxplot([all_models_per_image_bp[n],all_models_per_image_ll[n]])\n",
    "plt.xticks([1,2],[\"BP\",\"LL\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(f\"Model number {n}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ll = [item for sublist in all_models_per_image_ll for item in sublist]\n",
    "flat_bp = [item for sublist in all_models_per_image_bp for item in sublist]\n",
    "\n",
    "boxplotfgsm = plt.boxplot([flat_bp,flat_ll])#,showfliers=False)\n",
    "plt.xticks([1,2],[\"All bp models\",\"All ll models\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(\"Epsilons for misclassification for FGSM\")\n",
    "plt.show()\n",
    "\n",
    "meds = [item.get_ydata() for item in boxplotfgsm[\"medians\"]]\n",
    "print(meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bp_spectra = all_models_per_image_bp[scales_stringer_spectra]\n",
    "\n",
    "x = scales_stringer_spectra\n",
    "y = all_models_per_image_bp\n",
    "stringer_bp = [b for a, b in zip(x, y) if a]\n",
    "not_stringer_bp = [b for a, b in zip(x, y) if not a]\n",
    "y = all_models_per_image_ll\n",
    "stringer_ll = [b for a, b in zip(x, y) if a]\n",
    "not_stringer_ll = [b for a, b in zip(x, y) if not a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ll_stringer = [item for sublist in stringer_ll for item in sublist]\n",
    "flat_ll_not_stringer = [item for sublist in not_stringer_ll for item in sublist]\n",
    "\n",
    "boxplot = plt.boxplot([flat_ll_stringer,flat_ll_not_stringer],showfliers=False)\n",
    "plt.xticks([1,2],[\"Spectrum = TRUE\",\"Spectrum = FALSE\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(\"Epsilons for misclassification for FGSM on ll models\")\n",
    "plt.show()\n",
    "\n",
    "meds = [item.get_ydata() for item in boxplot[\"medians\"]]\n",
    "print(meds)\n",
    "print((meds[0]==meds[1]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_bp_stringer = [item for sublist in stringer_bp for item in sublist]\n",
    "flat_bp_not_stringer = [item for sublist in not_stringer_bp for item in sublist]\n",
    "\n",
    "plt.boxplot([flat_bp_stringer,flat_bp_not_stringer],showfliers=False)\n",
    "plt.xticks([1,2],[\"Spectrum = TRUE\",\"Spectrum = FALSE\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(\"Epsilons for misclassification for FGSM on bp models\")\n",
    "plt.show()\n",
    "\n",
    "meds = [item.get_ydata() for item in boxplot[\"medians\"]]\n",
    "print((meds[0]==meds[1]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ll_pgd = [item for sublist in all_models_per_image_ll_pgd for item in sublist]\n",
    "flat_bp_pgd = [item for sublist in all_models_per_image_bp_pgd for item in sublist]\n",
    "boxp = plt.boxplot([flat_bp_pgd,flat_ll_pgd])#,showfliers=False)\n",
    "plt.xticks([1,2],[\"All bp models\",\"All ll models\"])\n",
    "plt.ylabel(\"Critical epsilon\")\n",
    "plt.title(\"Epsilons for misclassification for PGD\")\n",
    "plt.show()\n",
    "\n",
    "meds = [item.get_ydata() for item in boxp[\"medians\"]]\n",
    "print(meds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
