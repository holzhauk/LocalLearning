{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2555e3",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12194db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import LocalLearning_copy as LocalLearning #replaced import from context because of issues with imports\n",
    "# LocalLearning_copy has the KHModel_bp, that one is not implemented in context (should be though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa20fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "375b9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible models to train \n",
    "models_path = Path(\"../data/models/L3UnitCIFAR10_ensemble\")\n",
    "file_names = os.listdir(llmodels_path)\n",
    "file_names = [fn for fn in file_names if os.path.isfile(llmodels_path / Path(fn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3448893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KHModel_bp(\n",
       "  (relu_h): ReLU()\n",
       "  (first_dense): Linear(in_features=3072, out_features=2000, bias=True)\n",
       "  (dense): Linear(in_features=2000, out_features=10, bias=False)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initilise the model\n",
    "file_name = 'kh_layer_cifar10.pty' # here you choose which state\n",
    "model_file = Path(file_name)\n",
    "trained_state = torch.load(models_path / model_file)\n",
    "\n",
    "modeltype = \"bp\" \n",
    "\n",
    "if modeltype == \"bp\": \n",
    "    model = LocalLearning.KHModel_bp\n",
    "    \n",
    "elif modeltype == \"ll\":\n",
    "    model = LocalLearning.KHModel\n",
    "    \n",
    "khmodel = model(trained_state) # change model type here, either KHModel (ll) or KHModel_bp (bp)\n",
    "khmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b1c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kh_layer_cifar10.pty\n"
     ]
    }
   ],
   "source": [
    "print(model_file) # double checking that the model_file is the one you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f313c",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e98c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters:\n",
    "BATCH_SIZE = 1000\n",
    "NUMBER_OF_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# all previous models are trained with these hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8476933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "khmodel.train()\n",
    "\n",
    "cifar10Train= LocalLearning.LpUnitCIFAR10(\n",
    "    root=\"../data/CIFAR10\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    p=khmodel.pSet[\"p\"],\n",
    ")\n",
    "\n",
    "TrainLoader = LocalLearning.DeviceDataLoader(\n",
    "    cifar10Train,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "cifar10Test= LocalLearning.LpUnitCIFAR10(\n",
    "    root=\"../data/CIFAR10\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    p=khmodel.pSet[\"p\"],\n",
    ")\n",
    "\n",
    "TestLoader = LocalLearning.DeviceDataLoader(\n",
    "    cifar10Test,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6fe4060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_size': 3072,\n",
       " 'hidden_size': 2000,\n",
       " 'n': 4.5,\n",
       " 'p': 3.0,\n",
       " 'tau_l': 49999.999999999956,\n",
       " 'k': 2,\n",
       " 'Delta': 0.4,\n",
       " 'R': 1.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khmodel.pSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6bea9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "AdamOpt = Adam(khmodel.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a36725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    data: DataLoader,\n",
    "    test: DataLoader,\n",
    "    model: LocalLearning.KHModel, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    std=None,\n",
    "    no_epochs=NUMBER_OF_EPOCHS,\n",
    "    checkpt_period=1,\n",
    "    loss_history=[],\n",
    "    test_history=[],\n",
    "    ):\n",
    "    with tqdm(range(1, no_epochs + 1), unit=\"epoch\") as tepoch:\n",
    "        tepoch.set_description(f\"Training time [epochs]\")\n",
    "        \n",
    "        for epoch in tepoch:\n",
    "            \n",
    "            cumm_loss = 0.0\n",
    "            model.train()\n",
    "            for batch_no, (features, labels) in enumerate(data):\n",
    "                preds = model(features)\n",
    "                loss = loss_fn(preds, labels)\n",
    "                cumm_loss += loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            loss_history.append(cumm_loss)\n",
    "            \n",
    "            freq_correct = 0\n",
    "            model.eval()\n",
    "            for batch_no, (features, labels) in enumerate(test):\n",
    "                preds = torch.argmax(model(features), dim=-1)\n",
    "                freq_correct += (torch.abs(preds - labels) == 0).sum()\n",
    "            \n",
    "            test_history.append(freq_correct / (len(test)*test.batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ca5ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save this model? y = Yes, n = Noy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntorch.save(\\n{\\n    \"fkhl3-path\": str(llmodels_path / model_file),\\n    \"fkhl3-state\": ll_trained_state,\\n    \"model_state_dict\": khmodel.state_dict(),\\n    \"loss_history\": loss_history,\\n    \"accuracy_history\": accuracy_history,\\n},\\nllmodels_path.parent / Path(\"KHModelCIFAR10_ensemble\") / Path(\"bp_KHModel_\" + str(model_file)),\\n)'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "#train(TrainLoader, TestLoader, khmodel, ce_loss, AdamOpt, loss_history=loss_history, test_history=accuracy_history)\n",
    "\n",
    "save = input(\"Save this model? y = Yes, n = No\")\n",
    "\n",
    "if save == y:\n",
    "    torch.save(\n",
    "    {\n",
    "        \"fkhl3-path\": str(llmodels_path / model_file),\n",
    "        \"fkhl3-state\": ll_trained_state,\n",
    "        \"model_state_dict\": khmodel.state_dict(),\n",
    "        \"loss_history\": loss_history,\n",
    "        \"accuracy_history\": accuracy_history,\n",
    "    },\n",
    "    llmodels_path.parent / Path(\"KHModelCIFAR10_ensemble\") / Path(\"bp_KHModel_\" + str(model_file)),\n",
    "    ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "loss_history_cpu = np.array([a.cpu().detach().numpy() for a in loss_history])\n",
    "accuracy_history_cpu = np.array([a.cpu().detach().numpy() for a in accuracy_history])\n",
    "axs[0].plot(loss_history_cpu)\n",
    "axs[0].set_xlabel(r\"t [epochs]\")\n",
    "axs[0].set_ylabel(r\"CE(t)\")\n",
    "axs[1].plot(accuracy_history_cpu)\n",
    "axs[1].set_xlabel(r\"t [epochs]\")\n",
    "axs[1].set_ylabel(r\"Accuracy(t)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
